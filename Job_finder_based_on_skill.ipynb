{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P6_2_Final_P3_.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC-EKzqQ1B59"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from collections import Counter\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "\n",
        "pd.set_option('display.max_columns', 10000)\n",
        "pd.set_option('display.max_rows', 10000)\n",
        "pd.set_option('display.max_colwidth', 1000)\n",
        "pd.set_option('display.width', 1000)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyw-b5kldKnI"
      },
      "source": [
        "## Data Input Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wJKR4P_dIMp"
      },
      "source": [
        "######################### Importing 1st Data-set ###################\n",
        "vacan=json.load(open('Vacancies 2.json'))\n",
        "########################## Importing 2nd Data-Set #################\n",
        "emp=json.load(open('employees2.json'))\n",
        "\n"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIWmfdBhuImL"
      },
      "source": [
        "##Code for Standardizing Dataset 2 According to format of Dataset 1\n",
        "for i in emp:\n",
        "  for m,k in i['Location'].items():\n",
        "    i[str(m)]=str(k)\n",
        "  del i['Location']"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO_dcZhU55pq"
      },
      "source": [
        "Basic Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW4e69271F9W"
      },
      "source": [
        "\n",
        "# Data Standardizing (Lower casing with one spacing in list sub-elements)\n",
        "def standard_list(list_1):\n",
        "    dummy_list_1=[]\n",
        "    for i in list_1:\n",
        "        dummy_list_1.append(\" \".join(i.lower().split()))\n",
        "    return dummy_list_1\n",
        "\n",
        "### Stemming(sno) function (only standardize list) returning stemmed list\n",
        "\n",
        "def stem_list(list_stem):\n",
        "  sno = SnowballStemmer('english')\n",
        "  sl1=[]\n",
        "  for i in list_stem:\n",
        "    i=\" \".join(i.lower().split())\n",
        "    sl2=(list(i.split(\" \")))\n",
        "    sl3=[]\n",
        "    for k in sl2:\n",
        "      sl3.append(sno.stem(k))\n",
        "    sl4=' '.join([str(item) for item in sl3])\n",
        "    #print(sl4)\n",
        "    sl1.append(sl4)\n",
        "  return sl1\n",
        "\n",
        "\n"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-kuZPadtBn0"
      },
      "source": [
        " def standardization(input_list):\n",
        "  # Standardizing soft and hard skills lists and eleminating repeated elements #\n",
        "  out_list1=[]\n",
        "  for i in input_list:\n",
        "    c_dict=i.copy()\n",
        "    for m,k in c_dict.items():\n",
        "      if m=='softSkills' or m=='hardSkills':\n",
        "        if isinstance(i[m],str):\n",
        "          k = k.split(\",\")\n",
        "          k = list(set(k))\n",
        "          c_dict[m]=k\n",
        "        else:\n",
        "          k = list(set(k))\n",
        "          c_dict[m]=k\n",
        "      else:\n",
        "        c_dict[m]=k\n",
        "    out_list1.append(c_dict)\n",
        "\n",
        "  out_list2=[]\n",
        "  for b in out_list1:\n",
        "    d_dict=b.copy()\n",
        "    for a in range(0,2): \n",
        "        for q,r in d_dict.items():\n",
        "          if isinstance(d_dict[q],list):\n",
        "            r=standard_list(r)\n",
        "            d_dict[q]=r\n",
        "          if q== 'hardSkills':\n",
        "            d_dict['hardSkills']=stem_list(r)\n",
        "    \n",
        "    out_list2.append(d_dict)\n",
        "  return out_list2"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKBoapS2lnSH"
      },
      "source": [
        "### Standardizing both datasets for model input\n",
        "vacan=standardization(vacan)\n",
        "emp=standardization(emp)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TpvdA6d1cqH"
      },
      "source": [
        "# Model Initiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWoEFk7K1GJQ"
      },
      "source": [
        "########### Hard skill matching ########\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "def sequence_similarity(a, b):\n",
        "    return SequenceMatcher(None, a, b).ratio()\n",
        "\n",
        "def equal_similarity_s(js,jd):\n",
        "  equal_list=[]\n",
        "  for i in jd:\n",
        "    for k in js:\n",
        "      if sequence_similarity(i,k) > 0.70 :\n",
        "        equal_list.append(1)\n",
        "  return ((sum(equal_list)/len(js)))\n",
        "\n",
        "\n",
        "def equal_similarity_h(js,jd):\n",
        "  equal_list=[]\n",
        "  for i in jd:\n",
        "    for k in js:\n",
        "      if i==k :\n",
        "        equal_list.append(1)\n",
        "  return ((sum(equal_list)/len(js)))"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxF47kse1GLr"
      },
      "source": [
        "###Scoring With sequence Algorithm\n",
        "def equal_model(job_seeker,job_description):\n",
        "\n",
        "  spacy_score=[]\n",
        "  spacy_score.append(equal_similarity_s(job_seeker['softSkills'],job_description['softSkills']))#1\n",
        "  hard_skills=(equal_similarity_h(job_seeker['hardSkills'],job_description['hardSkills']))#2\n",
        "  spacy_score.append(hard_skills)\n",
        "  exp_div=float((job_seeker['yearsOfExperience'])/(job_description['Experience']))#3\n",
        "  exp_div=exp_div*hard_skills\n",
        "\n",
        "  if exp_div>= 1:\n",
        "    spacy_score.append(1)\n",
        "  else:\n",
        "    spacy_score.append(exp_div)\n",
        "\n",
        "  sal_div=float((job_description['Salary'])/(job_seeker['salaryAim']))#4\n",
        "\n",
        "  if sal_div >= 1:\n",
        "    spacy_score.append(1)\n",
        "  else:\n",
        "    spacy_score.append(sal_div)\n",
        "  \n",
        "  if job_seeker['Country']== job_description['Country'] and job_seeker['City']== job_description['City']:#5\n",
        "    spacy_score.append(1)\n",
        "  elif job_seeker['Country']== job_description['Country']:\n",
        "    spacy_score.append(0.5)\n",
        "  else:\n",
        "    spacy_score.append(-0.5)\n",
        "\n",
        "  spacy_score=list(spacy_score)\n",
        "  weights_list=[0.15,0.25,0.25,0.20,0.15]\n",
        "  spacy_model_score=np.average(spacy_score, weights=weights_list) *100\n",
        "  return spacy_model_score\n",
        "\n"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVKhaXbC1qC2"
      },
      "source": [
        "## **Precription**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXKJARD11GZZ"
      },
      "source": [
        "#################################### Job Precption ########################## \n",
        "\n",
        "res_dict={}\n",
        "for sa in emp:\n",
        "  c=[]\n",
        "  ml=[]\n",
        "  for i in vacan:\n",
        "    b={}\n",
        "    score=equal_model(sa,i)\n",
        "    b['ID']=str(i['ID'])\n",
        "    b['Title']=str(i['title'])\n",
        "    b['Soft Skills']=str(i['softSkills'])\n",
        "    b['Hard Skills']=str(i['softSkills'])\n",
        "    b['Score']=equal_model(sa,i)\n",
        "    c.append(b)\n",
        "\n",
        "  ml= sorted(c, key=lambda x:x['Score'])\n",
        "  ml=ml[-3:]\n",
        "  ml=ml[::-1]\n",
        "  res_dict[str(sa['Name'])]=ml\n",
        "\n",
        "\n"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJqnl5ivplPL"
      },
      "source": [
        "######### Saving Json File ############\n",
        "import json\n",
        "\n",
        "with open('out_put.json', 'w') as fp:\n",
        "    json.dump(res_dict,fp, sort_keys=True, indent=4)"
      ],
      "execution_count": 83,
      "outputs": []
    }
  ]
}